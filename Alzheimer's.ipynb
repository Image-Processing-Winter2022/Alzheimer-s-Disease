{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXsgEINgwiVs"
      },
      "source": [
        "Step 1: Connecting to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUwVEREjwi0-",
        "outputId": "c14b3110-e52f-44a5-c581-f2904f7a5684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqpAsZD3w5Le"
      },
      "source": [
        "Step 2: Download the Alzheimer's Dataset directly from the Kaggle website."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q84xBwYY_ati"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7maKhVDPDYpU"
      },
      "outputs": [],
      "source": [
        "cp /content/drive/MyDrive/kaggle.json /content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjCOCNqrDkRY"
      },
      "outputs": [],
      "source": [
        "! chmod 600 /content/kaggle.json\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/\"\n",
        "! kaggle datasets download tourist55/alzheimers-dataset-4-class-of-images\n",
        "! unzip /content/alzheimers-dataset-4-class-of-images.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmh06IftzXmh"
      },
      "source": [
        "Step 3: Import the Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNjYPrSw_Fkh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import copy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import cv2\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.applications.vgg16 import VGG16,preprocess_input\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Input, Reshape, Permute, multiply, Dense, Flatten, GlobalAveragePooling2D\n",
        "import tensorflow as tf\n",
        "import itertools\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aObLRt_10iI"
      },
      "source": [
        "Step 4: Prepare the Training and the Validation Data for Training the network.\n",
        "        Rescaling and Resizing the images are also performed in this step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x3_rXlc23k-",
        "outputId": "970f9d04-2085-4d0d-8d3d-1516792182f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4098 images belonging to 4 classes.\n",
            "Found 1023 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "data_dir = '/content/Alzheimer_s Dataset/train'\n",
        "BATCH_SIZE = 64\n",
        "X = Y = 224\n",
        "data = ImageDataGenerator(vertical_flip = False, horizontal_flip = True, rotation_range = 5, width_shift_range = 0.1, height_shift_range = 0.1, samplewise_center=False, samplewise_std_normalization=False, rescale=1./255, data_format=None, validation_split=0.2)\n",
        "training = data.flow_from_directory(directory = data_dir, target_size = (X, Y), color_mode=\"rgb\",class_mode='categorical', batch_size=BATCH_SIZE, shuffle=True, seed=42, subset=\"training\")\n",
        "validation = data.flow_from_directory(directory = data_dir, target_size = (X, Y), color_mode=\"rgb\",class_mode='categorical', batch_size=BATCH_SIZE, shuffle=False, seed=42, subset=\"validation\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX7gVYMe2eTy"
      },
      "source": [
        "Step 5: Defining The Squeeze and Excitation Block (SE Block)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvUpAXG2kQ_p"
      },
      "outputs": [],
      "source": [
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "def squeeze_excite_block(input, ratio=16):\n",
        "    ''' Create a squeeze-excite block\n",
        "    Args:\n",
        "        input: input tensor\n",
        "        filters: number of output filters\n",
        "        k: width factor\n",
        "    Returns: a keras tensor\n",
        "    '''\n",
        "    init = input\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    filters = init.shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = GlobalAveragePooling2D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        se = Permute((3, 1, 2))(se)\n",
        "\n",
        "    x = multiply([init, se])\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSFDeoHc45cC"
      },
      "source": [
        "Step 6: Select the feature Descriptor (NasNetMobile, VGG16, Resnet50) and train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4u8irTQ3y0p"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Select the feature Descriptor by commenting and uncommenting:\n",
        "\n",
        "# VGG16:\n",
        "# model= tf.keras.applications.VGG16(input_shape= (X, Y, 3), include_top= False, weights='imagenet', input_tensor=None, pooling='None', classes=1000)\n",
        "\n",
        "# NasNetMobile:\n",
        "# model= tf.keras.applications.NASNetMobile(input_shape= (X, Y, 3), include_top= False, weights='imagenet', input_tensor=None, pooling=None, classes=1000)\n",
        "\n",
        "# Resnet50:\n",
        "model= tf.keras.applications.ResNet50(input_shape= (X, Y, 3), include_top= False, weights='imagenet', input_tensor=None, pooling=None, classes=1000)\n",
        "\n",
        "\n",
        "# Defining the MLP Classifier and building the model:\n",
        "model.trainable = True\n",
        "x = model.output\n",
        "x=squeeze_excite_block(x, ratio=6)\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(512,activation='relu',kernel_initializer='he_uniform')(x)\n",
        "x = keras.layers.Dropout(0.1)(x)\n",
        "x = Dense(128,activation='relu',kernel_initializer='he_uniform')(x)\n",
        "x = Dense(32,activation='relu',kernel_initializer='he_uniform')(x)\n",
        "predictions = Dense(4,activation='softmax')(x)\n",
        "model = keras.models.Model(inputs=model.input, outputs=predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hopJ_9mD6GOX"
      },
      "source": [
        "Step 7: Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGq5S22-6AYO"
      },
      "outputs": [],
      "source": [
        "def weighted_categorical_crossentropy(weights):\n",
        "    \"\"\"\n",
        "    A weighted version of keras.objectives.categorical_crossentropy\n",
        "    \n",
        "    Variables:\n",
        "        weights: numpy array of shape (C,) where C is the number of classes\n",
        "    \n",
        "    Usage:\n",
        "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
        "        loss = weighted_categorical_crossentropy(weights)\n",
        "        model.compile(loss=loss,optimizer='adam')\n",
        "    \"\"\"\n",
        "    \n",
        "    weights = K.variable(weights)\n",
        "        \n",
        "    def loss(y_true, y_pred):\n",
        "        # scale predictions so that the class probas of each sample sum to 1\n",
        "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
        "        # clip to prevent NaN's and Inf's\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "        # calc\n",
        "        loss = y_true * K.log(y_pred) * weights\n",
        "        loss = -K.sum(loss, -1)\n",
        "        return loss\n",
        "    \n",
        "    return loss\n",
        "\n",
        "\n",
        "METRICS = [tf.keras.metrics.BinaryAccuracy(name='accuracy'),tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall'),  tf.keras.metrics.AUC(name='auc')]\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6),loss=weighted_categorical_crossentropy(np.array([5121/717, 5121/52, 5121/2560, 5121/1792]).astype(float)),metrics=METRICS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI8trqkU6Mc-"
      },
      "source": [
        "Step 8 : Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgZ-Ls8D4Aih"
      },
      "outputs": [],
      "source": [
        "callback_model= keras.callbacks.ModelCheckpoint( '/content' + '/model.h5', monitor= \"val_auc\", verbose= 1, save_best_only= True, mode= \"max\")\n",
        "callback_CSV= keras.callbacks.CSVLogger('/content' + \"/model.log\", append=True)\n",
        "\n",
        "# Training the model\n",
        "history = model.fit_generator(training, steps_per_epoch= len(training),  epochs=500, verbose=1, validation_data=validation, validation_steps= len(validation), callbacks=[callback_model, callback_CSV])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS6PsOvq78_Z"
      },
      "source": [
        "Step 9: Plott the graph of loss and AUC of the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6C6feaA1dsX"
      },
      "outputs": [],
      "source": [
        "def MovingAverage (arr,window_size):\n",
        "  i = 0\n",
        "  moving_averages = []\n",
        "  while i < len(arr) - window_size + 1:\n",
        "    \n",
        "      # Calculate the average of current window\n",
        "      window_average = round(np.sum(arr[\n",
        "        i:i+window_size]) / window_size, 2)\n",
        "        \n",
        "      # Store the average of current\n",
        "      # window in moving average list\n",
        "      moving_averages.append(window_average)\n",
        "        \n",
        "      # Shift window to right by one position\n",
        "      i += 1\n",
        "    \n",
        "  return moving_averages\n",
        "\n",
        "\n",
        "window_size = 5\n",
        "\n",
        "import pandas as pd\n",
        "data = pd.read_csv('/content/model.log', delimiter = \",\", header = None)\n",
        "epoch = np.array(data[0][1:]).astype(float) + 1\n",
        "auc = MovingAverage(np.append(np.array(data[2][1:window_size]),np.array(data[2][1:])).astype(float),window_size)\n",
        "loss = MovingAverage(np.append(np.array(data[3][1:window_size]),np.array(data[3][1:])).astype(float),window_size)\n",
        "val_auc = MovingAverage(np.append(np.array(data[7][1:window_size]),np.array(data[7][1:])).astype(float),window_size)\n",
        "val_loss = MovingAverage(np.append(np.array(data[8][1:window_size]),np.array(data[8][1:])).astype(float),window_size)\n",
        "\n",
        "\n",
        "print(len(epoch))\n",
        "print(len(auc))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(epoch, auc, label='Training AUC', color='r')\n",
        "plt.plot(epoch, val_auc, label='Validation AUC', color='b')\n",
        "\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.legend(loc='lower right', fontsize=13)\n",
        "plt.ylabel('AUC', fontsize=16, weight='bold')\n",
        "plt.title('Training & Validation AUC.', fontsize=16, weight='bold')\n",
        "\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss', color='r')\n",
        "plt.plot(val_loss, label='Validation Loss', color='b')\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.legend(loc='upper right', fontsize=13)\n",
        "plt.ylabel('Cross Entropy', fontsize=16, weight='bold')\n",
        "plt.title('Training & Validation Loss', fontsize=15, weight='bold')\n",
        "plt.xlabel('Epoch', fontsize=15, weight='bold')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5KLXrf99HLT"
      },
      "source": [
        "Step 10: Calculating the Precision, Recall, and F1-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s-xhF0GQ74l"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def weighted_categorical_crossentropy(weights):\n",
        "    \"\"\"\n",
        "    A weighted version of keras.objectives.categorical_crossentropy\n",
        "    \n",
        "    Variables:\n",
        "        weights: numpy array of shape (C,) where C is the number of classes\n",
        "    \n",
        "    Usage:\n",
        "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
        "        loss = weighted_categorical_crossentropy(weights)\n",
        "        model.compile(loss=loss,optimizer='adam')\n",
        "    \"\"\"\n",
        "    \n",
        "    weights = K.variable(weights)\n",
        "        \n",
        "    def loss(y_true, y_pred):\n",
        "        # scale predictions so that the class probas of each sample sum to 1\n",
        "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
        "        # clip to prevent NaN's and Inf's\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "        # calc\n",
        "        loss = y_true * K.log(y_pred) * weights\n",
        "        loss = -K.sum(loss, -1)\n",
        "        return loss\n",
        "    \n",
        "    return loss\n",
        "\n",
        "def loss(y_true, y_pred):\n",
        "    # scale predictions so that the class probas of each sample sum to 1\n",
        "    y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
        "    # clip to prevent NaN's and Inf's\n",
        "    y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "    # calc\n",
        "    loss = y_true * K.log(y_pred) * weights\n",
        "    loss = -K.sum(loss, -1)\n",
        "    return loss\n",
        "\n",
        "# Loading the model\n",
        "model= keras.models.load_model(\"/content/drive/MyDrive/model.h5\", custom_objects={\"weighted_categorical_crossentropy\":weighted_categorical_crossentropy,\"loss\":loss})    \n",
        "\n",
        "# Comput different metrics\n",
        "\n",
        "Y_pred = model.predict(validation)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print(classification_report(validation.classes, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U69TOSH9SE7"
      },
      "source": [
        "Step 11: Calculate and plot the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLt0CDQGR0jm"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title, weight='bold', fontsize=16)\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, fontsize=14)\n",
        "    plt.yticks(tick_marks, classes, fontsize=14)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\", fontsize=12, weight='bold',\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label', fontsize=16, weight='bold')\n",
        "    plt.xlabel('Predicted label', fontsize=16, weight='bold')\n",
        "\n",
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(validation.classes, y_pred)\n",
        "np.set_printoptions(precision=2)\n",
        "print(cnf_matrix)\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plt.figure(figsize=(10, 10))\n",
        "plot_confusion_matrix(cnf_matrix, classes=['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryDemented'],normalize=True,title='Normalized Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13k-TXh0DSct"
      },
      "source": [
        "Step 12: Plot the feature maps of some layers of the network for a sample input image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VdzKxu86djZ"
      },
      "outputs": [],
      "source": [
        "# Plot the sample Image\n",
        "plt.imshow(validation[0][0][0])\n",
        "\n",
        "# Build a model for plotting the feature maps\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "feature_map_model = keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "feature_maps  = feature_map_model.predict(np.expand_dims(validation[0][0][0],axis = 0))\n",
        "\n",
        "# Select some layers of the network and plot the feature maps\n",
        "feature_maps_list = [1,5,20]\n",
        "square = 5\n",
        "for fmap in feature_maps_list:\n",
        "  print(fmap)\n",
        "  ix = 1\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for _ in range(square):\n",
        "    for _ in range(square):\n",
        "      ax = plt.subplot(square, square, ix)\n",
        "      ax.set_xticks([])\n",
        "      ax.set_yticks([])\n",
        "      plt.imshow(feature_maps[fmap][0][:,:,ix-1])\n",
        "      ix += 1\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDVKO3vJFUpT"
      },
      "source": [
        "Step 13: Copute the attention map for the actived class using GradCam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiqxvHfPGxja"
      },
      "outputs": [],
      "source": [
        "\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer as well as the output predictions\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # This is the gradient of the output neuron (top predicted or chosen)\n",
        "    # with regard to the output feature map of the last conv layer\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    # then sum all the channels to obtain the heatmap class activation\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def save_and_display_gradcam(img, heatmap, cam_path=\"cam.jpg\", alpha=0.6):\n",
        "    # Load the original image\n",
        "    # img = keras.preprocessing.image.load_img(img_path)\n",
        "    # img = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Use jet colormap to colorize heatmap\n",
        "    jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "    # Use RGB values of the colormap\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "    \n",
        "    # Create an image with RGB colorized heatmap\n",
        "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Superimpose the heatmap on original image\n",
        "    superimposed_img = (jet_heatmap/255) * alpha + img\n",
        "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "    # Save the superimposed image\n",
        "    superimposed_img.save(cam_path)\n",
        "\n",
        "    # Display Grad CAM\n",
        "    display(Image(cam_path))\n",
        "\n",
        "\n",
        "# Generate class activation heatmap\n",
        "\n",
        "layer_outputs = [layer.name for layer in model.layers]\n",
        "last_conv_layer_name = layer_outputs[-13]\n",
        "heatmap = make_gradcam_heatmap(np.expand_dims(validation[0][0][0],axis = 0), model, last_conv_layer_name)\n",
        "\n",
        "# Display heatmap\n",
        "plt.figure();plt.matshow(heatmap)\n",
        "\n",
        "plt.figure();save_and_display_gradcam(validation[0][0][0], heatmap)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "new_Alzheimer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}